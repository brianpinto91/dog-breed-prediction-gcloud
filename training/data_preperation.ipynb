{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the image dataset and metadata files\n",
    "\n",
    "The dog breed image dataset is made available by Stanford and can by downloaded from [here](http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar)  \n",
    "The dataset can be divided into train and test set by downloading the information files from [here](http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the information files\n",
    "full_list = loadmat(\"data/file_list.mat\")\n",
    "train_list = loadmat(\"data/train_list.mat\")\n",
    "test_list = loadmat(\"data/test_list.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert the information files to a useful format\n",
    "def create_img_info_df(mat_dict_file):\n",
    "    image_info_list = []\n",
    "    for i in range(mat_dict_file['file_list'].shape[0]):\n",
    "        file_path = mat_dict_file['file_list'][i][0][0]\n",
    "        breed = re.search(r'(?<=-)\\w*', file_path).group()\n",
    "        image_info_list.append([file_path, breed])\n",
    "    image_info_df = pd.DataFrame(image_info_list, columns=[\"file_path\", \"breed\"])\n",
    "    return image_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set_info_df = create_img_info_df(full_list)\n",
    "train_info_df = create_img_info_df(train_list)\n",
    "test_info_df = create_img_info_df(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The complete dataset has 20580 images\n",
      "the train set has 12000 images\n",
      "the test set has 8580 images\n"
     ]
    }
   ],
   "source": [
    "print(\"The complete dataset has {} images\".format(full_set_info_df.shape[0]))\n",
    "print(\"the train set has {} images\".format(train_info_df.shape[0]))\n",
    "print(\"the test set has {} images\".format(test_info_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a list of unique breeds\n",
    "breeds = list(full_set_info_df.groupby(by=\"breed\").count().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique breeds: 120\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of unique breeds: {}\".format(len(breeds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionaries to map breed to class_id and vice-versa\n",
    "breed_to_class_id = {x:y for x, y in zip(breeds, range(len(breeds)))}\n",
    "class_id_to_breed = {y:x for x,y in breed_to_class_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump as json files for use during prediction\n",
    "with open(\"data/breed_to_class_id.json\", \"w\") as filehandler:\n",
    "    json.dump(breed_to_class_id, filehandler)\n",
    "with open(\"data/class_id_to_breed.json\", \"w\") as filehandler:\n",
    "    json.dump(class_id_to_breed, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert and save the train and test images to hd5 format to make the reading fast during the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_train_file = h5py.File(\"data/train.h5\", 'w')\n",
    "h5_test_file = h5py.File(\"data/test.h5\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the h5 files with appropriate size (i.e 224 by 224 to be used with resnet) and fill with zeros\n",
    "train_features = h5_train_file.create_dataset('data', shape=(len(train_info_df), 224, 224, 3), dtype=np.uint8, fillvalue=0)\n",
    "train_labels = h5_train_file.create_dataset('labels', shape=(len(train_info_df),1), dtype=np.uint8)\n",
    "test_features = h5_test_file.create_dataset('data', shape=(len(test_info_df), 224, 224, 3), dtype=np.uint8, fillvalue=0)\n",
    "test_labels = h5_test_file.create_dataset('labels', shape=(len(test_info_df),1), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert all the images to a defined width and height\n",
    "def resizeImage(size, image):\n",
    "    image.thumbnail(size, Image.ANTIALIAS)\n",
    "    background = Image.new('RGB', size, (0, 0, 0))\n",
    "    background.paste(image, (int((size[0] - image.size[0]) / 2), int((size[1] - image.size[1]) / 2)))\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write image and label to h5_train_file and h5_test_file\n",
    "for i in range(len(train_info_df)):\n",
    "    image_file_name = train_info_df.iloc[i]['file_path']\n",
    "    img = Image.open(\"data/Images/\" + image_file_name)\n",
    "    img = resizeImage((224,224), img)\n",
    "    img = np.array(img)\n",
    "    train_features[i] = img #write to h5 dataset\n",
    "    train_labels[i] = breed_to_class_id[train_info_df.iloc[i]['breed']] #write to h5 dataset\n",
    "    \n",
    "for i in range(len(test_info_df)):\n",
    "    image_file_name = test_info_df.iloc[i]['file_path']\n",
    "    img = Image.open(\"data/Images/\" + image_file_name)\n",
    "    img = resizeImage((224,224), img)\n",
    "    img = np.array(img)\n",
    "    test_features[i] = img #write to h5 dataset\n",
    "    test_labels[i] = breed_to_class_id[test_info_df.iloc[i]['breed']] #write to h5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_train_file.close()\n",
    "h5_test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
